{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies: ogr2ogr, topojson\n",
    "\n",
    "Note: This script only updates the ddf--concepts and ddf--entities files, meaning they need to exist before executing this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from ddf_utils.str import to_concept_id\n",
    "from ddf_utils.index import create_index_file\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "import shutil\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape2json(src, trg):\n",
    "    cmd = \"ogr2ogr -f GeoJSON \" + trg + \" \" + src\n",
    "    print \"Running command: \" + cmd\n",
    "    subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geo2topo(src, trg):\n",
    "    args = \" --id-property HASC_2 -p municipality=NAME_2 -- \"\n",
    "    cmd = \"topojson -o \" + trg + args + src\n",
    "    print \"Running command: \" + cmd\n",
    "    subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract map IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_map_ids(data):\n",
    "    ids = data[[\"HASC_2\",\"NAME_2\"]].copy()\n",
    "    ids.rename(columns={\"HASC_2\": \"map_id\",\"NAME_2\": \"name\"}, inplace=True)\n",
    "    \n",
    "    # Fix irregularities manually\n",
    "    ids[\"map_id\"].iloc[268] = \"SE.VG.ML\"\n",
    "    ids[\"map_id\"].iloc[187] = \"SE.VG.KN\"\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_concepts(out_dir, map_type, map_file, map_object):\n",
    "    concept_file = os.path.join(out_dir, \"ddf--concepts.csv\")\n",
    "    \n",
    "    if not os.path.isfile(concept_file):\n",
    "        print \"Error: File not found \" + concept_file\n",
    "        return False\n",
    "    else:\n",
    "        print \"Adding new map info...\"\n",
    "        data = pd.read_csv(concept_file, encoding=\"utf-8\")\n",
    "        data.loc[data[\"concept\"] == \"municipality\",\"map_type\"] = map_type\n",
    "        data.loc[data[\"concept\"] == \"municipality\",\"map_file\"] = map_file\n",
    "        data.loc[data[\"concept\"] == \"municipality\",\"map_object\"] = map_object\n",
    "        data.fillna(\"\")\n",
    "        \n",
    "        # Add new concepts if it does not exist already    \n",
    "        if \"map_id\" not in data[\"concept\"].values:\n",
    "            new_concepts = [{\"concept\":\"map_id\",\"name\": \"Map ID\",\"concept_type\": \"string\"},\\\n",
    "                            {\"concept\":\"map_type\",\"name\": \"Map format\",\"concept_type\": \"string\"},\\\n",
    "                            {\"concept\":\"map_file\",\"name\": \"Path to map file\",\"concept_type\": \"string\"},\\\n",
    "                            {\"concept\":\"map_object\",\"name\": \\\n",
    "                             \"Name of JSON object with geo shapes (map_type specific)\",\"concept_type\": \"string\"}]\n",
    "            df_new_concepts = pd.DataFrame(new_concepts)\n",
    "            data = data.append(df_new_concepts,ignore_index=True)\n",
    "            del df_new_concepts\n",
    "            \n",
    "        data = data[[\"concept\", \"name\", \"concept_type\", \"map_file\", \"map_object\", \"map_type\"]] # Reorder columns\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_entities(out_dir, ids):\n",
    "    entities_file = os.path.join(out_dir,\"ddf--entities--municipality.csv\")\n",
    "    \n",
    "    if not os.path.isfile(entities_file):\n",
    "        print \"Error: File not found \" + entities_file\n",
    "        return False\n",
    "    else:\n",
    "        entities = pd.read_csv(entities_file, encoding=\"utf-8\",\\\n",
    "                               converters={\"municipality\": lambda x: str(x), \"county\": lambda x: str(x)})\n",
    "\n",
    "        # Hack needed due to encoding issues (create a tmp column used when merging the dataframes)\n",
    "        if \"map_id\" not in entities.columns:\n",
    "            entities[\"tmp\"] = entities[\"name\"].map(to_concept_id)\n",
    "            ids[\"tmp\"] = ids[\"name\"].map(to_concept_id)\n",
    "            entities = entities.set_index(\"tmp\")\n",
    "            ids = ids.set_index(\"tmp\")\n",
    "            new_entities = pd.concat([entities, ids[\"map_id\"]], axis=1)\n",
    "    \n",
    "            return new_entities.sort_values(by=\"municipality\")\n",
    "        else:\n",
    "            return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filenames etc\n",
    "out_dir = os.path.join(os.pardir,\"output\")\n",
    "src = os.path.join(os.pardir, \"src\")\n",
    "\n",
    "# Misc\n",
    "zip_file = \"SWE_adm_shp.zip\"\n",
    "topojson_object = \"municipalities.json\"\n",
    "topojson_file = \"shapes_municipalities.json\"\n",
    "download = False\n",
    "\n",
    "# Raw data\n",
    "geo_url = \"http://biogeo.ucdavis.edu/data/gadm2.8/shp/SWE_adm_shp.zip\" # Geo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main script\n",
    "\n",
    "Produces a topojson file with the following structure:\n",
    "\n",
    "```\n",
    "topojson_file = \n",
    "\n",
    "{\n",
    "    type: \"\"\n",
    "    transform: {},\n",
    "    arcs: [],\n",
    "    objects: {\n",
    "                topojson_object: {}\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Where **topojson_object** is a geometry collection with all the polygons. For more info, see the [TopoJSON wiki](https://github.com/mbostock/topojson/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: ogr2ogr -f GeoJSON municipalities.json ../src/SWE_adm_shp/SWE_adm2.shp\n",
      "Running command: topojson -o ../output/shapes_municipalities.json --id-property HASC_2 -p municipality=NAME_2 -- municipalities.json\n",
      "Adding new map info...\n",
      "Printing ../output/ddf--concepts.csv\n",
      "Printing ../output/ddf--entities--municipality.csv\n",
      "Creating index files...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Download file\n",
    "    if download:\n",
    "        o = urllib.URLopener()\n",
    "        zip_name = os.path.join(src, zip_file)\n",
    "        o.retrieve(geo_url, zip_name)\n",
    "    else:\n",
    "        # Use downloaded file\n",
    "        zip_name = os.path.join(src, zip_file)\n",
    "\n",
    "    # Extract all\n",
    "    zip_dir = os.path.join(src, zip_file.split(\".\")[0])\n",
    "    with zipfile.ZipFile(zip_name, \"r\") as z:\n",
    "        z.extractall(zip_dir)\n",
    "\n",
    "    # Convert shape files to GeoJSON, then GeoJSON to TopoJSON\n",
    "    shape_file = os.path.join(zip_dir, \"SWE_adm2.shp\")\n",
    "    shape2json(shape_file, topojson_object)\n",
    "    path = os.path.join(out_dir, topojson_file)\n",
    "    geo2topo(topojson_object, path)\n",
    "\n",
    "    # Add concept properties\n",
    "    data = update_concepts(out_dir, \"topojson\", topojson_file, topojson_object.split(\".\")[0])\n",
    "    path = os.path.join(out_dir, \"ddf--concepts.csv\")\n",
    "    print \"Printing \" + path\n",
    "    data.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    # Extract map IDs\n",
    "    path = os.path.join(zip_dir, \"SWE_adm2.csv\")\n",
    "    data = pd.read_csv(path, encoding=\"utf-8\")\n",
    "    ids = extract_map_ids(data)\n",
    "    \n",
    "    # Add map IDs to entities\n",
    "    data = update_entities(out_dir, ids)\n",
    "    path = os.path.join(out_dir, \"ddf--entities--municipality.csv\")\n",
    "    print \"Printing \" + path\n",
    "    data.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    # Cleanup\n",
    "    shutil.rmtree(zip_dir)\n",
    "    os.remove(topojson_object)\n",
    "    \n",
    "    # Create index file\n",
    "    print(\"Creating index files...\")\n",
    "    create_index_file(out_dir)\n",
    "    \n",
    "    # Free memory\n",
    "    del data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
